{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import pyro\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from train_setup import setup_directories, setup_tensorboard, setup_logging\n",
    "from train_setup import setup_dataloaders\n",
    "# From datasets import get_attr_max_min\n",
    "from utils import EMA, seed_all\n",
    "from dscm import DSCM\n",
    "from hvae2 import HVAE2\n",
    "import torch.nn.functional as F\n",
    "from pgm.train_pgm import sup_epoch, eval_epoch\n",
    "from pgm.utils_pgm import check_nan, update_stats, calculate_loss, plot_cf\n",
    "from dscm import vae_preprocess\n",
    "from pgm.layers import TraceStorage_ELBO\n",
    "from pgm.chest_pgm import FlowPGM\n",
    "\n",
    "from train_cf import norm, loginfo, preprocess, inv_preprocess, get_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading predictor checkpoint: ../pgm/checkpoints/age_race_sex_finding/sup_aux_mimic_crop/checkpoint.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "# Load predictors\n",
    "predictor_path = '../pgm/checkpoints/age_race_sex_finding/sup_aux_mimic_crop/checkpoint.pt'\n",
    "print(f'\\nLoading predictor checkpoint: {predictor_path}')\n",
    "predictor_checkpoint = torch.load(predictor_path)\n",
    "predictor_args = Hparams()\n",
    "predictor_args.update(predictor_checkpoint['hparams'])\n",
    "\n",
    "predictor_args.loss_norm = \"l2\"\n",
    "\n",
    "predictor = FlowPGM(predictor_args).cuda()\n",
    "predictor.load_state_dict(predictor_checkpoint['ema_model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading PGM checkpoint: ../pgm/checkpoints/age_race_sex_finding/sup_pgm_mimic_crop/checkpoint.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm_path = '../pgm/checkpoints/age_race_sex_finding/sup_pgm_mimic_crop/checkpoint.pt'\n",
    "print(f'\\nLoading PGM checkpoint: {pgm_path}')\n",
    "pgm_checkpoint = torch.load(pgm_path)\n",
    "pgm_args = Hparams()\n",
    "pgm_args.update(pgm_checkpoint['hparams'])\n",
    "pgm = FlowPGM(pgm_args).cuda()\n",
    "pgm.load_state_dict(pgm_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading VAE checkpoint: ../checkpoints/age_race_sex_finding/mimic_crop_256_64_beta_3/checkpoint.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load deep VAE\n",
    "beta = 3\n",
    "vae_path = f\"../checkpoints/age_race_sex_finding/mimic_crop_256_64_beta_{beta}/checkpoint.pt\"\n",
    "\n",
    "print(f'\\nLoading VAE checkpoint: {vae_path}')\n",
    "vae_checkpoint = torch.load(vae_path)\n",
    "vae_args = Hparams()\n",
    "vae_args.batch_size = 10\n",
    "\n",
    "vae_args.update(vae_checkpoint['hparams'])\n",
    "\n",
    "vae = HVAE2(vae_args).cuda()\n",
    "vae.load_state_dict(vae_checkpoint['ema_model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_name': 'MIMIC_crop generation', 'seed': 11, 'mixed_precision': False, 'is_unit_test_config': False, 'data': {'batch_size': 16, 'num_workers': 12, 'pin_memory': True, 'input_channels': 1, 'weights': 'None', 'augmentations': {'resize': [256, 64], 'center_crop': 'None', 'random_rotation': 0, 'horizontal_flip': False, 'vertical_flip': False, 'random_crop': 'None', 'random_color_jitter': 0.1, 'random_erase_scale': [0.0, 0.0], 'sharp': 0.0}, 'prop_train': 1.0, '_target_': 'data_handling.chest_xray.MimicDataModule', 'dataset': 'mimic', 'domain': 'None', 'cache': False}, 'trainer': {'name': 'base', 'lr': 0.001, 'num_epochs': 400, 'patience_for_scheduler': 10, 'metric_to_monitor': 'Val/loss', 'metric_to_monitor_mode': 'min', 'val_check_interval': 'None', 'weight_decay': 0.0, 'use_train_augmentations': True, 'loss': 'ce', 'contrastive_temperature': 0.1, 'return_two_views': False, 'finetune_path': 'None', 'device': [0], 'max_steps': 'None', 'freeze_encoder': False}, 'model': {'encoder_name': 'resnet18', 'pretrained': False}}\n",
      "Train df: \n",
      "sex\n",
      "Male      0.52424\n",
      "Female    0.47576\n",
      "Name: proportion, dtype: float64\n",
      "disease\n",
      "No Finding          0.553934\n",
      "Pleural Effusion    0.446066\n",
      "Name: proportion, dtype: float64\n",
      "race\n",
      "White    0.781186\n",
      "Black    0.179704\n",
      "Asian    0.039111\n",
      "Name: proportion, dtype: float64\n",
      "Len dataset 62336\n",
      "Validation df: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/tx1215/heartflow_mimic_crop/causal_models/dscm/../../data_handling/chest_xray.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['disease'] = df['disease'].replace({'No Finding': 0, 'Pleural Effusion': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Male      0.516252\n",
      "Female    0.483748\n",
      "Name: proportion, dtype: float64\n",
      "disease\n",
      "No Finding          0.541031\n",
      "Pleural Effusion    0.458969\n",
      "Name: proportion, dtype: float64\n",
      "race\n",
      "White    0.764848\n",
      "Black    0.188804\n",
      "Asian    0.046348\n",
      "Name: proportion, dtype: float64\n",
      "Len dataset 9968\n",
      "Test df: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/tx1215/heartflow_mimic_crop/causal_models/dscm/../../data_handling/chest_xray.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['disease'] = df['disease'].replace({'No Finding': 0, 'Pleural Effusion': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Male      0.522024\n",
      "Female    0.477976\n",
      "Name: proportion, dtype: float64\n",
      "disease\n",
      "No Finding          0.546651\n",
      "Pleural Effusion    0.453349\n",
      "Name: proportion, dtype: float64\n",
      "race\n",
      "White    0.772491\n",
      "Black    0.186999\n",
      "Asian    0.040511\n",
      "Name: proportion, dtype: float64\n",
      "Len dataset 30535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/tx1215/heartflow_mimic_crop/causal_models/dscm/../../data_handling/chest_xray.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['disease'] = df['disease'].replace({'No Finding': 0, 'Pleural Effusion': 1})\n"
     ]
    }
   ],
   "source": [
    "dataloaders = setup_dataloaders(vae_args, cache=False, shuffle_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [00:16<00:00, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test | race_acc: 0.8424 - race_rocauc: 0.8671 - sex_acc: 0.9358 - sex_rocauc: 0.9857 - finding_acc: 0.8583 - finding_rocauc: 0.9253 - age: 7.6448\n"
     ]
    }
   ],
   "source": [
    "elbo_fn = TraceStorage_ELBO(num_particles=1)\n",
    "test_stats = eval_epoch(predictor, dataloaders['valid'])\n",
    "print('test | '+' - '.join(f'{k}: {v:.4f}' for k, v in test_stats.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples  = copy.deepcopy(dataloaders['train'].dataset.get_samples())\n",
    "n_train = len(dataloaders['train'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/age_race_sex_finding/mimic_crop_beta_3_soft_lr_1e4_lagrange_lr_1_damping_10/3000_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "args = Hparams()\n",
    "\n",
    "dscm_dir = \"mimic_crop_beta_3_soft_lr_1e4_lagrange_lr_1_damping_10\"\n",
    "\n",
    "\n",
    "# which_checkpoint=\"21000_checkpoint\"\n",
    "which_checkpoint=\"3000_checkpoint\"\n",
    "\n",
    "args.load_path = f'checkpoints/age_race_sex_finding/{dscm_dir}/{which_checkpoint}.pt'\n",
    "print(args.load_path)\n",
    "dscm_checkpoint = torch.load(args.load_path )\n",
    "args.update(dscm_checkpoint['hparams'])\n",
    "model = DSCM(args, pgm, predictor, vae)\n",
    "args.cf_particles =1\n",
    "model.load_state_dict(dscm_checkpoint['ema_model_state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "# Set model require_grad to False\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_VMIN,_VMAX = -120, 120\n",
    "def undo_norm(pa):\n",
    "    for k, v in pa.items():\n",
    "        if k ==\"age\":\n",
    "            pa[k] = (v + 1) / 2 *100 # [-1,1] -> [0,100]\n",
    "    return pa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "class MidpointNormalize(colors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        v_ext = np.max( [ np.abs(self.vmin), np.abs(self.vmax) ] )\n",
    "        x, y = [-v_ext, self.midpoint, v_ext], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot(x, fig=None, ax=None, nrows=1, cmap='Greys_r', norm=None, cbar=False, set_cbar_ticks=True, logger=None):\n",
    "    m, n = nrows, x.shape[0] // nrows\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(m, n, figsize=(n * 4, 8))\n",
    "    im = []\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            idx = (i, j) if m > 1 else j\n",
    "            ax = [ax] if n == 1 else ax\n",
    "            _x = x[i * n + j].squeeze()\n",
    "            if norm is not None:\n",
    "                norm = MidpointNormalize(vmin=_x.min(), midpoint=0, vmax=_x.max())\n",
    "                # norm = colors.TwoSlopeNorm(vmin=_x.min(), vcenter=0., vmax=_x.max())\n",
    "            # logger.info(f\"ax[idx] is: {type(ax[idx])}, m: {m}, n: {n}, shape: {np.shape(ax[idx])}\")\n",
    "            _im = ax[idx].imshow(_x, cmap=cmap, norm=norm)\n",
    "            im.append(_im)\n",
    "            ax[idx].axes.xaxis.set_ticks([])\n",
    "            ax[idx].axes.yaxis.set_ticks([])\n",
    "\n",
    "    if cbar:\n",
    "        if fig:\n",
    "            fig.subplots_adjust(wspace=-0.275, hspace=0.25)\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                idx = [i, j] if m > 1 else j\n",
    "                # cbar_ax = fig.add_axes([\n",
    "                #     ax[idx].get_position().x0 + 0.0025, # left\n",
    "                #     ax[idx].get_position().y1, # bottom\n",
    "                #     0.003, # width\n",
    "                #     ax[idx].get_position().height # height\n",
    "                # ])\n",
    "                cbar_ax = fig.add_axes([\n",
    "                    ax[idx].get_position().x0,\n",
    "                    ax[idx].get_position().y0 - 0.015,\n",
    "                    ax[idx].get_position().width,\n",
    "                    0.0075\n",
    "                ])\n",
    "                cbar = plt.colorbar(im[i * n + j], cax=cbar_ax,\n",
    "                                    orientation=\"horizontal\")  # , ticks=mticker.MultipleLocator(25)) #, ticks=mticker.AutoLocator())\n",
    "                # cbar.ax.tick_params(rotation=0)\n",
    "                # cbar.ax.locator_params(nbins=5)\n",
    "                _x = x[i * n + j].squeeze()\n",
    "\n",
    "                if set_cbar_ticks:\n",
    "                    d = 20\n",
    "                    _vmin, _vmax = _x.min().abs().item(), _x.max().item()\n",
    "                    _vmin = -(_vmin - (_vmin % d))\n",
    "                    _vmax = _vmax - (_vmax % d)\n",
    "                    lt = [_vmin, 0, _vmax]\n",
    "\n",
    "                    if (np.abs(_vmin) - 0) > d or (_vmax - 0) > d:\n",
    "                        lt.insert(1, _vmin // 2)\n",
    "                        lt.insert(-2, _vmax // 2)\n",
    "                    cbar.set_ticks(lt)\n",
    "                else:\n",
    "                    cbar.ax.locator_params(nbins=5)\n",
    "                    cbar.formatter.set_powerlimits((0, 0))\n",
    "\n",
    "                cbar.outline.set_visible(False)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_plot(save_path, obs, cfs, do, var_cf_x=None, num_images=10):\n",
    "    _ = plot_cf(obs['x'], cfs['x'], \n",
    "        inv_preprocess({k: v for k, v in obs.items() if k != 'x'}),  # pa\n",
    "        inv_preprocess({k: v for k, v in cfs.items() if k != 'x'}),  # cf_pa\n",
    "        inv_preprocess(do), # Counterfactual variance per pixel\n",
    "        var_cf_x = var_cf_x,\n",
    "        num_images=num_images,\n",
    "    )\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def plot_cf(x, cf_x, pa, cf_pa, do, var_cf_x=None, num_images=8, logger=None):\n",
    "    n = num_images  # 8 columns\n",
    "    x = (x[:n].detach().cpu() + 1) * 127.5\n",
    "    cf_x = (cf_x[:n].detach().cpu() + 1) * 127.5\n",
    "    # logger.info(f\"x: {x.size()}\")\n",
    "    fs = 12  # font size\n",
    "    m = 3 if var_cf_x is None else 4  # nrows\n",
    "    s = 5\n",
    "    fig, ax = plt.subplots(m, n, figsize=(n * s, m * s))\n",
    "    # fig, ax = plt.subplots(m, n, figsize=(n*s, m*s+2))\n",
    "    # logger.info(f\"ax: {np.shape(ax)}\")\n",
    "    # logger.info(f\"ax[0]: {type(ax[0])} {np.shape(ax[0])}, m: {m}, s: {s}, n: {n}\")\n",
    "    _, _ = plot(x, ax=ax[0])\n",
    "    _, _ = plot(cf_x, ax=ax[1])\n",
    "    _, _ = plot(cf_x - x, ax=ax[2], fig=fig, cmap='RdBu_r', cbar=True,\n",
    "                norm=MidpointNormalize(midpoint=0))\n",
    "    if var_cf_x is not None:\n",
    "        _, _ = plot(var_cf_x[:n].detach().sqrt().cpu(),\n",
    "                    fig=fig, cmap='jet', ax=ax[3], cbar=True, set_cbar_ticks=False)\n",
    "\n",
    "    sex_categories = ['male', 'female']  # 0,1\n",
    "    race_categories = ['White', 'Asian', 'Black']  # 0,1,2\n",
    "    finding_categories = ['No finding', 'Finding']\n",
    "\n",
    "    for j in range(n):\n",
    "        msg = ''\n",
    "        for i, (k, v) in enumerate(do.items()):\n",
    "            if k == 'sex':\n",
    "                vv = sex_categories[int(v[j].item())]\n",
    "                kk = 's'\n",
    "            elif k == 'age':\n",
    "                vv = str(v[j].item())\n",
    "                kk = 'a'\n",
    "            elif k == 'race':\n",
    "                vv = race_categories[int(torch.argmax(v[j], dim=-1))]\n",
    "                kk = 'r'\n",
    "            elif k =='finding':\n",
    "                vv = finding_categories[int(v[j].item())]\n",
    "                kk = 'f'\n",
    "            msg += kk + '{{=}}' + vv\n",
    "            msg += ', ' if (i + 1) < len(list(do.keys())) else ''\n",
    "\n",
    "        s = str(sex_categories[int(pa['sex'][j].item())])\n",
    "        r = str(race_categories[int(torch.argmax(pa['race'][j], dim=-1))])\n",
    "        a = str(int(pa['age'][j].item()))\n",
    "        f = str(finding_categories[int(pa['finding'][j].item())])\n",
    "\n",
    "\n",
    "        ax[0, j].set_title(f'a={a}, s={s}, \\n r={r}, f={f}',\n",
    "                           pad=8, fontsize=fs - 4, multialignment='center', linespacing=1.5)\n",
    "        ax[1, j].set_title(f'do(${msg}$)', fontsize=fs, pad=10)\n",
    "\n",
    "        # plot counterfactual\n",
    "        cf_s = str(sex_categories[int(cf_pa['sex'][j].item())])\n",
    "        cf_a = str(np.round(cf_pa['age'][j].item(), 1))\n",
    "        cf_r = str(race_categories[int(torch.argmax(cf_pa['race'][j], dim=-1))])\n",
    "        cf_f = str(finding_categories[int(cf_pa['finding'][j].item())])\n",
    "\n",
    "        ax[1, j].set_xlabel(\n",
    "            rf'$\\widetilde{{a}}{{=}}{cf_a}, \\ \\widetilde{{s}}{{=}}{cf_s}, \\ \\widetilde{{r}}{{=}}{cf_r},  \\ \\widetilde{{f}}{{=}}{cf_f}$',\n",
    "            labelpad=9, fontsize=fs - 4, multialignment='center', linespacing=1.25)\n",
    "\n",
    "    ax[0, 0].set_ylabel('Observation', fontsize=fs + 2, labelpad=8)\n",
    "    ax[1, 0].set_ylabel('Counterfactual', fontsize=fs + 2, labelpad=8)\n",
    "    ax[2, 0].set_ylabel('Treatment Effect', fontsize=fs + 2, labelpad=8)\n",
    "    if var_cf_x is not None:\n",
    "        ax[3, 0].set_ylabel('Uncertainty', fontsize=fs + 2, labelpad=8)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Hparams()\n",
    "args.save_dir = f\"results/{dscm_dir}/{which_checkpoint}\"\n",
    "os.makedirs(args.save_dir , exist_ok=True)\n",
    "\n",
    "model.pgm.eval()\n",
    "model.predictor.eval()\n",
    "model.vae.eval()\n",
    "dag_variables = list(model.pgm.variables.keys())\n",
    "preds = {k: [] for k in dag_variables}\n",
    "targets = {k: [] for k in dag_variables}\n",
    "# args.save_dir = f\"../../results/{dscm_dir}/{which_checkpoint}\"\n",
    "# os.makedirs(args.save_dir , exist_ok=True)\n",
    "# loader = tqdm(enumerate(dataloaders['test']), total=len(\n",
    "#     dataloaders['test']), mininterval=0.1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_counterfactuals(model, dataloader, predictor, do_pa=None):\n",
    "    ' this can consume lots of memory if dataset is large'\n",
    "    model.pgm.eval()\n",
    "    model.predictor.eval()\n",
    "    predictor.eval()\n",
    "    model.vae.eval()\n",
    "    dag_variables = list(model.pgm.variables.keys())\n",
    "    preds = {k: [] for k in dag_variables}\n",
    "    targets = {k: [] for k in dag_variables}\n",
    "    plt_counter = 0\n",
    "    cf_particles=1\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        # if plt_counter>10:\n",
    "        #     continue\n",
    "        plt_counter+=1\n",
    "        bs = batch['x'].shape[0]\n",
    "        batch = preprocess(batch)\n",
    "        # randomly intervene on a single parent, where pa_k ~ p(pa_k)\n",
    "        do = {}\n",
    "        do_k = copy.deepcopy(do_pa) if do_pa else random.choice(dag_variables) \n",
    "\n",
    "        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs]\n",
    "        do = preprocess(norm(do))\n",
    "\n",
    "        # get counterfactual pa\n",
    "        pa = {k: v for k, v in batch.items() if k != 'x'}     \n",
    "        _pa = vae_preprocess(\n",
    "            vae_args, {k: v.clone() for k, v in pa.items()})   \n",
    "        # cf_pa = model.pgm.counterfactual(obs=pa, intervention=do, num_particles=1)       \n",
    "        \n",
    "        # get counterfactual x\n",
    "        out = model.forward(batch, do, elbo_fn, cf_particles=cf_particles)\n",
    "        cf_pa = out['cf_pa']\n",
    "        _cf_pa = vae_preprocess(\n",
    "                vae_args, {k: v.clone() for k, v in cf_pa.items()})\n",
    "\n",
    "        nans = 0\n",
    "        for k, v in out['cfs'].items():\n",
    "        # for k, v in cfs.items():\n",
    "            k_nans = torch.isnan(v).sum()\n",
    "            nans += k_nans\n",
    "            if k_nans > 0:\n",
    "                print(f'\\nFound {k_nans} nans in cf {k}.')\n",
    "        if nans > 0:\n",
    "            continue\n",
    "\n",
    "        predict_out = predictor.predict(**out['cfs'])\n",
    "        # predict_out = model.predictor.predict(**cfs)\n",
    "\n",
    "\n",
    "        for k, v in predict_out.items():\n",
    "            preds[k].extend(v)\n",
    "        \n",
    "        # interventions are the targets for prediction\n",
    "        for k in targets.keys():\n",
    "            if k in do.keys():\n",
    "                targets[k].extend(\n",
    "                    do[k]\n",
    "                )\n",
    "            else:\n",
    "                targets[k].extend(\n",
    "                    cf_pa[k]\n",
    "                )\n",
    "\n",
    "        if plt_counter<20:\n",
    "            save_path = os.path.join(args.save_dir, f'test_{do_k}_{plt_counter}_cfs.png')\n",
    "            save_plot(save_path, batch, out['cfs'], do,  \n",
    "                      var_cf_x = out['var_cf_x'],\n",
    "                      num_images=4)\n",
    "            # plot_cf(batch['x'], cf_x, pa, cf_pa, do)\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "\n",
    "    stats = {}\n",
    "    for k in dag_variables:\n",
    "        if k in ['sex', 'finding']:\n",
    "            stats[k+'_rocauc'] = roc_auc_score(\n",
    "                targets[k].numpy(), preds[k].numpy(), average='macro')\n",
    "            stats[k+'_acc'] = (targets[k].squeeze(-1) == torch.round(preds[k])).sum().item() / targets[k].shape[0]\n",
    "        elif k == 'age':\n",
    "            stats[k] = torch.mean(torch.abs(targets[k] - preds[k])).item() * 100\n",
    "        elif k == 'race':\n",
    "            num_corrects = (targets[k].argmax(-1) == preds[k].argmax(-1)).sum()\n",
    "            stats[k + \"_acc\"] = num_corrects.item() / targets[k].shape[0]\n",
    "            stats[k + \"_rocauc\"] = roc_auc_score(\n",
    "                targets[k].numpy(),\n",
    "                preds[k].numpy(),\n",
    "                multi_class=\"ovr\",\n",
    "                average=\"macro\",)\n",
    "    return stats, preds, targets\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_random(model, dataloader, do_pa=None):\n",
    "    ' this can consume lots of memory if dataset is large'\n",
    "    model.pgm.eval()\n",
    "    model.predictor.eval()\n",
    "    model.vae.eval()\n",
    "    dag_variables = list(model.pgm.variables.keys())\n",
    "    preds = {k: [] for k in dag_variables}\n",
    "    targets = {k: [] for k in dag_variables}\n",
    "    plt_counter = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        plt_counter+=1\n",
    "        bs = batch['x'].shape[0]\n",
    "        # randomly intervene on a single parent, where pa_k ~ p(pa_k)\n",
    "        do = {}\n",
    "        do_k = copy.deepcopy(do_pa) if do_pa else random.choice(dag_variables) \n",
    "        do[do_k] = train_samples[do_k].clone()[torch.randperm(n_train)][:bs]\n",
    "\n",
    "        # get counterfactual pa\n",
    "        batch = preprocess(batch)\n",
    "        do = preprocess(norm(do))\n",
    "        pa = {k: v for k, v in batch.items() if k != 'x'}        \n",
    "        cf_pa = model.pgm.counterfactual(obs=pa, intervention=do, num_particles=1)       \n",
    "        \n",
    "        # get counterfactual x\n",
    "        _cf_pa = vae_preprocess(args, {k: v.clone() for k, v in cf_pa.items()})   \n",
    "        cf_loc, _ = model.vae.sample(parents=_cf_pa, return_loc=True)\n",
    "\n",
    "        cf_x = cf_loc\n",
    "\n",
    "        cfs = {'x': cf_x.clamp(min=-1, max=1)}\n",
    "        cfs.update(cf_pa)\n",
    "\n",
    "        nans = 0\n",
    "        for k, v in cfs.items():\n",
    "            k_nans = torch.isnan(v).sum()\n",
    "            nans += k_nans\n",
    "            if k_nans > 0:\n",
    "                print(f'\\nFound {k_nans} nans in cf {k}.')\n",
    "        if nans > 0:\n",
    "            continue\n",
    "\n",
    "        out = model.predictor.predict(**cfs)\n",
    "\n",
    "        for k, v in out.items():\n",
    "            preds[k].extend(v)\n",
    "        \n",
    "        # interventions are the targets for prediction\n",
    "        for k in targets.keys():\n",
    "            if k in do.keys():\n",
    "                targets[k].extend(\n",
    "                    do[k]\n",
    "                )\n",
    "                # print(f\"do {k}: {do[k].size()}\")\n",
    "            else:\n",
    "                targets[k].extend(\n",
    "                    cf_pa[k]\n",
    "                )\n",
    "                # print(f\"cf_pa {k}: {cf_pa[k].size()}\")\n",
    "        \n",
    "        if plt_counter<2:\n",
    "            pass\n",
    "            # plot_cf_rec(batch['x'], cf_loc, pa, cf_pa, do, rec_loc)\n",
    "            # plot_cf(batch['x'], cf_x, pa, cf_pa, do)\n",
    "\n",
    "    for k, v in preds.items():\n",
    "        preds[k] = torch.stack(v).squeeze().cpu()\n",
    "        targets[k] = torch.stack(targets[k]).squeeze().cpu()\n",
    "        # print(f'{k} | preds: {preds[k].shape} - targets: {targets[k].shape}')\n",
    "\n",
    "    stats = {}\n",
    "    for k in dag_variables:\n",
    "        if k in ['sex', 'finding']:\n",
    "            stats[k+'_rocauc'] = roc_auc_score(\n",
    "                targets[k].numpy(), preds[k].numpy(), average='macro')\n",
    "            stats[k+'_acc'] = (targets[k].squeeze(-1) == torch.round(preds[k])).sum().item() / targets[k].shape[0]\n",
    "        elif k == 'age':\n",
    "            stats[k] = torch.mean(torch.abs(targets[k] - preds[k])).item() * 100\n",
    "        elif k == 'race':\n",
    "            preds_k = F.one_hot(torch.argmax(F.softmax(preds[k], dim=-1), dim=-1))\n",
    "            # print(f\"preds_k: {preds_k.size()}\")\n",
    "            stats[k+'_acc'] = accuracy_score(targets[k].to(torch.int32) ,preds_k.to(torch.int32))\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [06:13<00:00,  1.67it/s]\n",
      "100%|██████████| 623/623 [06:15<00:00,  1.66it/s]\n",
      "100%|██████████| 623/623 [06:14<00:00,  1.66it/s]\n",
      "100%|██████████| 623/623 [06:15<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_sex | race_acc: -0.012 - race_rocauc: -0.021 - sex_rocauc: -0.001 - sex_acc: -0.003 - finding_rocauc: -0.004 - finding_acc: -0.004 - age: 0.380\n",
      "do_race | race_acc: -0.042 - race_rocauc: -0.078 - sex_rocauc: -0.001 - sex_acc: -0.001 - finding_rocauc: -0.001 - finding_acc: 0.000 - age: 0.757\n",
      "do_age | race_acc: -0.012 - race_rocauc: -0.011 - sex_rocauc: -0.002 - sex_acc: -0.002 - finding_rocauc: 0.011 - finding_acc: 0.013 - age: 3.829\n",
      "do_finding | race_acc: -0.005 - race_rocauc: -0.011 - sex_rocauc: -0.003 - sex_acc: -0.003 - finding_rocauc: 0.019 - finding_acc: 0.017 - age: 1.334\n"
     ]
    }
   ],
   "source": [
    "stats_do = {\n",
    "    'sex':{}, \n",
    "    'race':{}, \n",
    "    'age':{},\n",
    "    'finding':{}\n",
    "            }\n",
    "preds_do = {\n",
    "    'sex':{}, \n",
    "    'race':{}, \n",
    "    'age':{},\n",
    "    'finding':{}\n",
    "            }\n",
    "targets_do = {\n",
    "    'sex':{}, \n",
    "    'race':{}, \n",
    "    'age':{},\n",
    "    'finding':{}\n",
    "            }\n",
    "\n",
    "# base_stats = {\n",
    "#     'race_rocauc':0.8468415443534377,\n",
    "#     'sex_rocauc': 0.996207396871533,\n",
    "#     'finding_rocauc':0.9443025803264049,\n",
    "#     'age':6.17903545498848 ,\n",
    "# }\n",
    "\n",
    "for do_v in stats_do.keys():\n",
    "    stats, preds, targets = eval_counterfactuals(model, dataloaders['valid'], predictor, do_pa=do_v)\n",
    "    # stats = eval_random(model, dataloaders['valid'], do_pa=do_v)\n",
    "    stats_do[do_v] = stats\n",
    "\n",
    "# stats, preds, targets = eval_counterfactuals(model, dataloaders['valid'], predictor_for_evaluation)\n",
    "# # stats = eval_random(model, dataloaders['valid'])\n",
    "# stats_do['random'] = stats\n",
    "\n",
    "for do_v in stats_do.keys():\n",
    "    print(f'do_{do_v} | '+' - '.join(f'{k}: {v-test_stats[k]:.3f}' for k,v in stats_do[do_v].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_sex | race_acc: 0.830 - race_rocauc: 0.846 - sex_rocauc: 0.985 - sex_acc: 0.932 - finding_rocauc: 0.922 - finding_acc: 0.854 - age: 8.025\n",
      "do_race | race_acc: 0.801 - race_rocauc: 0.789 - sex_rocauc: 0.985 - sex_acc: 0.935 - finding_rocauc: 0.924 - finding_acc: 0.858 - age: 8.402\n",
      "do_age | race_acc: 0.830 - race_rocauc: 0.856 - sex_rocauc: 0.984 - sex_acc: 0.933 - finding_rocauc: 0.936 - finding_acc: 0.871 - age: 11.474\n",
      "do_finding | race_acc: 0.837 - race_rocauc: 0.856 - sex_rocauc: 0.983 - sex_acc: 0.933 - finding_rocauc: 0.944 - finding_acc: 0.875 - age: 8.979\n"
     ]
    }
   ],
   "source": [
    "for do_v in stats_do.keys():\n",
    "    print(f'do_{do_v} | '+' - '.join(f'{k}: {v:.3f}' for k,v in stats_do[do_v].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian_breast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
