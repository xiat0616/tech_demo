{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Optional\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "from torchvision.transforms import ToTensor, Resize, CenterCrop\n",
    "from data_handling.base import BaseDataModuleClass\n",
    "from datetime import datetime\n",
    "from data_handling.caching import SharedCache\n",
    "from hydra import compose, initialize\n",
    "# from data_handling.chest_xray import MimicDataset, MimicDataModule\n",
    "from data_handling.sampler import SamplerFactory\n",
    "from torch.utils.data import DataLoader\n",
    "from causal_models.train_setup import setup_dataloaders\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# from data_handling.exclude_id_padchest import exclude_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_name': 'chest X ray generation', 'seed': 11, 'mixed_precision': False, 'is_unit_test_config': False, 'data': {'batch_size': 1, 'num_workers': 12, 'pin_memory': True, 'input_channels': 1, 'weights': 'None', 'augmentations': {'resize': [224, 224], 'center_crop': 'None', 'random_rotation': 0, 'horizontal_flip': False, 'vertical_flip': False, 'random_crop': 'None', 'random_color_jitter': 0.1, 'random_erase_scale': [0.0, 0.0], 'sharp': 0.0}, 'prop_train': 1.0, '_target_': 'data_handling.pad_chest.PadChestDataModule', 'dataset': 'PadChest', 'domain': 'None', 'cache': False, 'seg_target_list': ['Left-Lung', 'Right-Lung', 'Heart']}, 'trainer': {'name': 'base', 'lr': 0.001, 'num_epochs': 400, 'patience_for_scheduler': 10, 'metric_to_monitor': 'Val/loss', 'metric_to_monitor_mode': 'min', 'val_check_interval': 'None', 'weight_decay': 0.0, 'use_train_augmentations': True, 'loss': 'ce', 'contrastive_temperature': 0.1, 'return_two_views': False, 'finetune_path': 'None', 'device': [0], 'max_steps': 'None', 'freeze_encoder': False}, 'model': {'encoder_name': 'resnet18', 'pretrained': False}}\n",
      "Len 61714\n",
      "pneumonia\n",
      "False    0.967706\n",
      "True     0.032294\n",
      "Name: proportion, dtype: float64\n",
      "Manufacturer\n",
      "Imaging     0.626535\n",
      "Phillips    0.373465\n",
      "Name: proportion, dtype: float64\n",
      "Len 6911\n",
      "pneumonia\n",
      "False    0.962958\n",
      "True     0.037042\n",
      "Name: proportion, dtype: float64\n",
      "Manufacturer\n",
      "Imaging     0.614383\n",
      "Phillips    0.385617\n",
      "Name: proportion, dtype: float64\n",
      "Len 17123\n",
      "pneumonia\n",
      "False    0.965543\n",
      "True     0.034457\n",
      "Name: proportion, dtype: float64\n",
      "Manufacturer\n",
      "Imaging     0.630088\n",
      "Phillips    0.369912\n",
      "Name: proportion, dtype: float64\n",
      "Dataset size (3.2 GiB) fits in cache limit (24 GiB). Allocating space to cache all 17123 samples.\n"
     ]
    }
   ],
   "source": [
    "class Hparams:\n",
    "    def update(self, dict):\n",
    "        for k, v in dict.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "args = Hparams()\n",
    "args.hps = \"padchest224_224_with_seg\"\n",
    "args.parents_x = [\"sex\", \"age\"]\n",
    "args.data = Hparams()\n",
    "args.data.seg_target_list=[\"Left-Lung\", \"Right-Lung\", \"Heart\"]\n",
    "args.batch_size = 1\n",
    "dataloaders = setup_dataloaders(args=args, cache=False, shuffle_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataloaders['train'].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_set.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(example['finding'].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find abnormal cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Function to plot images for a single example\n",
    "# def plot_images(example_batch, idx):\n",
    "#     \"\"\"\n",
    "#     Plots images from an example batch with detailed titles.\n",
    "#     \"\"\"\n",
    "#     fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 1 row, 4 columns\n",
    "\n",
    "#     # Set the main title for the figure\n",
    "#     fig.suptitle(\n",
    "#         f\"Index: {idx}, ImageID: {example_batch['shortpath']}, \"\n",
    "#         f\"Left-Lung Volume: {example_batch['Left-Lung_volume']}, \"\n",
    "#         f\"Right-Lung Volume: {example_batch['Right-Lung_volume']}, \"\n",
    "#         f\"Heart Volume: {example_batch['Heart_volume']}\",\n",
    "#         fontsize=14\n",
    "#     )\n",
    "\n",
    "#     # Titles and corresponding keys for the images\n",
    "#     keys_titles = [\n",
    "#         (\"x\", \"Image\"),\n",
    "#         (\"Left-Lung\", \"Left Lung\"),\n",
    "#         (\"Right-Lung\", \"Right Lung\"),\n",
    "#         (\"Heart\", \"Heart\"),\n",
    "#     ]\n",
    "\n",
    "#     # Plot images\n",
    "#     for ax, (key, title) in zip(axes, keys_titles):\n",
    "#         if key in example_batch:\n",
    "#             ax.imshow(example_batch[key][0], cmap='gray')\n",
    "#         ax.set_title(title)\n",
    "#         ax.axis(\"off\")  # Hide axes for a cleaner look\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # List to store ImageIDs of subjects in the specified range\n",
    "# selected_ImageIDs = []\n",
    "# selected_IDs = []\n",
    "\n",
    "# # Create a DataLoader for the dataset\n",
    "# data_loader = DataLoader(train_set, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "# # Iterate over the dataset with a progress bar\n",
    "# for batch_idx, batch in tqdm(enumerate(data_loader), desc=\"Processing subjects\", total=len(data_loader)):\n",
    "#     # Check all subjects in the batch\n",
    "#     selected_indices = (\n",
    "#         ((batch['Left-Lung_volume'] >= 0) & (batch['Left-Lung_volume'] < 100)) |\n",
    "#         ((batch['Right-Lung_volume'] >= 0) & (batch['Right-Lung_volume'] < 100)) |\n",
    "#         ((batch['Heart_volume'] >= 1200) & (batch['Heart_volume'] < 2000))\n",
    "#     )\n",
    "\n",
    "#     # Process subjects in the selected range\n",
    "#     for i in selected_indices.nonzero(as_tuple=True)[0]:\n",
    "#         global_idx = batch_idx * 32 + i  # Calculate global index\n",
    "#         example_batch = {key: batch[key][i] for key in batch}  # Extract the selected example\n",
    "\n",
    "#         # Add the ImageID to the list\n",
    "#         selected_ImageIDs.append(example_batch['shortpath'])\n",
    "#         selected_IDs.append(global_idx)\n",
    "#         # Plot the images for the current example\n",
    "#         plot_images(example_batch, global_idx)\n",
    "\n",
    "# # Print the list of selected ImageIDs\n",
    "# print(\"Selected ImageIDs:\", selected_ImageIDs)\n",
    "# print(\"Selected IDs:\", selected_IDs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update abnormal Image IDs based on observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_IDs = [60769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id_ in bad_IDs:\n",
    "#     example_batch = train_set.__getitem__(id_)\n",
    "\n",
    "\n",
    "#     # Create a figure with four subplots in a 1x4 grid\n",
    "#     fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 1 row, 4 columns\n",
    "\n",
    "#     # Set the main title for the figure\n",
    "#     fig.suptitle(\n",
    "#             f\"Index: {id_}, ImageID: {example_batch['shortpath']}, \"\n",
    "#             f\"Left-Lung Volume: {example_batch['Left-Lung_volume']}, \"\n",
    "#             f\"Right-Lung Volume: {example_batch['Right-Lung_volume']}, \"\n",
    "#             f\"Heart Volume: {example_batch['Heart_volume']}\",\n",
    "#             fontsize=14\n",
    "#         )\n",
    "\n",
    "#     # Plot the 'x' image in the first subplot\n",
    "#     axes[0].imshow(example_batch['x'][0], cmap='gray')\n",
    "#     axes[0].set_title(\"Image\")\n",
    "#     axes[0].axis(\"off\")  # Hide axes for a cleaner look\n",
    "\n",
    "#     # Plot the 'Left-Lung' image in the second subplot\n",
    "#     axes[1].imshow(example_batch['Left-Lung'][0], cmap='gray')\n",
    "#     axes[1].set_title(\"Left Lung\")\n",
    "#     axes[1].axis(\"off\")\n",
    "\n",
    "#     # Plot the 'Right-Lung' image in the third subplot\n",
    "#     axes[2].imshow(example_batch['Right-Lung'][0], cmap='gray')\n",
    "#     axes[2].set_title(\"Right Lung\")\n",
    "#     axes[2].axis(\"off\")\n",
    "\n",
    "#     # Plot the 'Heart' image in the fourth subplot\n",
    "#     axes[3].imshow(example_batch['Heart'][0], cmap='gray')\n",
    "#     axes[3].set_title(\"Heart\")\n",
    "#     axes[3].axis(\"off\")\n",
    "\n",
    "#     # Adjust layout and display the figure\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(example_batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the CSV\n",
    "# manual_df = pd.read_csv(\"manual_labelled_padchest.csv\")\n",
    "\n",
    "# # Ensure train_set is defined and contains the required data\n",
    "# # Assuming train_set.__getitem__() returns a dictionary with 'shortpath'\n",
    "\n",
    "# # Create the 'bad' column if it doesn't exist\n",
    "# if 'bad' not in manual_df.columns:\n",
    "#     manual_df['bad'] = 0  # Default to 0 for all rows\n",
    "\n",
    "# # Loop through bad_IDs and update the 'bad' column in manual_df\n",
    "# for id_ in bad_IDs:\n",
    "#     sample = train_set.__getitem__(id_)\n",
    "#     shortpath = sample['shortpath']  # The specific shortpath\n",
    "#     # Locate rows in manual_df where 'ImageID' matches the shortpath\n",
    "#     manual_df.loc[manual_df['ImageID'] == shortpath, 'bad'] = 1\n",
    "\n",
    "# # Save the updated DataFrame back to the CSV file\n",
    "# manual_df.to_csv(\"manual_labelled_padchest.csv\", index=False)\n",
    "\n",
    "# # Optional: Print a confirmation\n",
    "# print(\"The 'bad' column has been updated for rows matching the bad_IDs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming bad_IDs is defined\n",
    "\n",
    "# # Read the CSV\n",
    "# manual_df = pd.read_csv(\"manual_labelled_padchest.csv\")\n",
    "\n",
    "# # Ensure train_set is defined and contains the required data\n",
    "# # Assuming train_set.__getitem__() returns a dictionary with 'shortpath'\n",
    "# subset_list = []\n",
    "\n",
    "# # Loop through bad_IDs and get the subset of manual_df\n",
    "# for id_ in bad_IDs:\n",
    "#     sample = train_set.__getitem__(id_)\n",
    "#     shortpath = sample['shortpath']  # The specific shortpath\n",
    "#     subset = manual_df[manual_df['ImageID'] == shortpath]  # Filter manual_df\n",
    "#     subset_list.append(subset)\n",
    "\n",
    "# # Combine all subsets into one DataFrame (if needed)\n",
    "# final_subset = pd.concat(subset_list, ignore_index=True)\n",
    "\n",
    "# # Print the final subset\n",
    "# print(final_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find max and min volumes of each seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modes = ['train']\n",
    "\n",
    "# # Initialize dictionaries for min and max volumes and their indices\n",
    "# seg_target_list = dataloaders['train'].dataset.seg_target_list\n",
    "# min_volumes = {k: float('inf') for k in seg_target_list}\n",
    "# max_volumes = {k: float('-inf') for k in seg_target_list}\n",
    "# min_index = {k: -1 for k in seg_target_list}\n",
    "# max_index = {k: -1 for k in seg_target_list}\n",
    "\n",
    "# # Iterate through modes and datasets\n",
    "# for mode in modes:\n",
    "#     print(f\"Processing mode: {mode}\")\n",
    "    \n",
    "#     for idx, batch in enumerate(tqdm(dataloaders[mode], desc=f\"Processing {mode} mode\")):\n",
    "#         for k in seg_target_list:\n",
    "#             # Extract volume for the current segmentation target\n",
    "#             volume = batch[f\"{k}_volume\"]\n",
    "\n",
    "#             # Update min volume and index\n",
    "#             current_min = volume.min().item()\n",
    "#             if current_min < min_volumes[k]:\n",
    "#                 min_volumes[k] = current_min\n",
    "#                 min_index[k] = idx\n",
    "\n",
    "#             # Update max volume and index\n",
    "#             current_max = volume.max().item()\n",
    "#             if current_max > max_volumes[k]:\n",
    "#                 max_volumes[k] = current_max\n",
    "#                 max_index[k] = idx\n",
    "\n",
    "# # Print results\n",
    "# print(\"Max Volumes:\", max_volumes)\n",
    "# print(\"Min Volumes:\", min_volumes)\n",
    "# print(\"Min Indices:\", min_index)\n",
    "# print(\"Max Indices:\", max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian_breast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
